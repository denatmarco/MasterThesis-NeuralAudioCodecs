```markdown
# ðŸ“˜ Third-Octave VQ Encoder â€“ Unified Command Line Interface

This repository provides two command-line tools for working with the **Third-Octave Vector-Quantized Encoder**:

1. **Training CLI (`train_trioct.py`)**
   Used to prepare audio datasets and train the encoder.

2. **Embedding Extraction CLI (`embedding_cli.py`)**
   Used to extract continuous latent embeddings (`z_e`) from a trained encoder.

Both tools ensure reproducibility, consistency, and ease of use.

---

# ðŸ“¦ Installation

Install required dependencies:

~~~bash
pip install -r requirements.txt
~~~

The CLIs are:

- `train_trioct.py`
- `embedding_cli.py`

---

# ðŸš€ Training CLI â€“ Usage Overview

General syntax:

~~~bash
python train_trioct.py <action> [options]
~~~

Available actions:

- `prepare`
- `train`
- `full`

Each requires:

- `--input` dataset path  
- `--output` checkpoints directory  

---

# ðŸ”§ Commands (Training CLI)

## 1. prepare

Converts `.wav` / `.mp3` files to standardized **16 kHz WAV** format.

Pipeline:

- recursive scan  
- audio loading + resampling  
- WAV conversion  
- output to `output/temp_wavs/`

**Example:**

~~~bash
python train_trioct.py prepare \
    --input C:/Datasets/Lion \
    --output ./checkpoints_mammals
~~~

Output directory:

```
./checkpoints_mammals/temp_wavs/
```

---

## 2. train

Trains the Third-Octave VQ encoder.

Options:

- `--epochs` (40 default)  
- `--batch`  (32 default)  
- `--lr`     (2e-3 default)  
- `--device` (cuda default)  
- `--checkpoint` resume from file  

**Example:**

~~~bash
python train_trioct.py train \
    --input ./checkpoints_mammals/temp_wavs \
    --output ./checkpoints_mammals \
    --epochs 40 \
    --batch 32 \
    --lr 0.002
~~~

Generated:

```
encoder_final.pt
training_summary.json
```

---

## 3. full

Runs `prepare â†’ train`.

**Example:**

~~~bash
python train_trioct.py full \
    --input C:/Datasets/Lion \
    --output ./checkpoints_mammals \
    --epochs 40 \
    --batch 32
~~~

---

# ðŸ“„ Output Structure (Training)

```
output/
â”‚
â”œâ”€â”€ temp_wavs/
â”œâ”€â”€ encoder_final.pt
â””â”€â”€ training_summary.json
```

---

# ðŸ§ª Training Notes

- Ensure dataset cleanliness (no denoising performed).  
- GPU recommended (`--device cuda`).  
- Keep outputs separate per dataset.  
- Use `--checkpoint` to resume training.

---

# ðŸ“˜ Embedding Extraction CLI â€“ Usage Overview

General syntax:

~~~bash
python embedding_cli.py <action> [options]
~~~

Available actions:

- `audit`
- `extract`
- `full`

Each requires:

- `--input` dataset  
- `--output` embedding folder  
- `--checkpoint` encoder `.pt`  
- `--window`, `--batch`, etc.

Embeddings are saved as `.txt` matrices.

---

# ðŸ”§ Commands (Embedding CLI)

## 1. audit

Generates segmentation metadata.

Steps:

- collect audio  
- convert to WAV  
- segment waveforms  
- export `audit_segments.csv`  

**Example:**

~~~bash
python embedding_cli.py audit \
    --input C:/Datasets/GTZAN \
    --output C:/Datasets/GTZAN/trioct/win_1/embeddings \
    --checkpoint ./checkpoints_music/bands_vq_encoder_full.pt \
    --window 1.0
~~~

Output:

```
output/audit_segments.csv
```

---

## 2. extract

Extracts embeddings for each segmented audio window.

Pipeline:

- audioâ†’WAV  
- segmentation  
- encoder forward pass  
- save embedding as `.txt`  
- produce `fragments_index.csv`  

Embedding shape:

```
(latent_dim, time_frames)
```

**Example:**

~~~bash
python embedding_cli.py extract \
    --input C:/Datasets/GTZAN \
    --output C:/Datasets/GTZAN/trioct/win_1/embeddings \
    --checkpoint ./checkpoints_music/bands_vq_encoder_full.pt \
    --window 1.0 \
    --batch 256
~~~

Output structure:

```
output/
â”‚
â”œâ”€â”€ fragments_index.csv
â”œâ”€â”€ file_subfolder/
â”‚      â”œâ”€â”€ audio_seg0000.txt
â”‚      â”œâ”€â”€ audio_seg0001.txt
â”‚      â””â”€â”€ ...
â””â”€â”€ ...
```

---

## 3. full

Runs `audit â†’ extract`.

**Example:**

~~~bash
python embedding_cli.py full \
    --input C:/Datasets/GTZAN \
    --output C:/Datasets/GTZAN/trioct/win_1/embeddings \
    --checkpoint ./checkpoints_music/bands_vq_encoder_full.pt \
    --window 1.0 \
    --batch 256
~~~

Outputs:

- `audit_segments.csv`  
- `fragments_index.csv`  
- all `.txt` embeddings  

---

# ðŸ“„ Output Files Overview

| File                   | Description                 |
|------------------------|-----------------------------|
| audit_segments.csv     | segmentation metadata       |
| fragments_index.csv    | list of fragments           |
| *_segXXXX.txt          | embedding matrices          |

Load an embedding:

~~~python
import numpy as np
z = np.loadtxt("path/to/fragment.txt")
~~~

---

# ðŸ§ª Extraction Notes

- Use the same window size across datasets.  
- Increase `--batch` for speed (SSD recommended).  
- Do not mix datasets in the same output folder.  
- Audio is automatically resampled to match encoder requirements.
```
